<!doctype html>
<html lang="en-us">

  <head>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-W1QPLQGQSQ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-W1QPLQGQSQ');
</script>

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="author" content="Shobhita Sundaram">
  <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->

  <meta http-equiv='cache-control' content='no-cache'>
  <meta http-equiv='expires' content='0'>
  <meta http-equiv='pragma' content='no-cache'>
  <title>
    
      About &middot; Shobhita Sundaram
    
  </title>

  <link rel="stylesheet" href="css/poole.css">
  <link rel="stylesheet" href="css/syntax.css">
  <link rel="stylesheet" href="css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/public/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="http://localhost:4000/public/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="http://localhost:4000/atom.xml">
</head>

  <body class="theme-base-08">

    <div class="sidebar">
  <div class="container" >
    <div class="sidebar-about">
      <a href="images/ssundaram_headshot.png"><img style="width:85%;max-width:100%;display:block;margin-left:auto;margin-right:auto" alt="profile photo" src="images/ssundaram_headshot.png" class="hoverZoomLink"></a>
      <h1>
        <a href="" style="text-align: center">
          Shobhita Sundaram
        </a>
      </h1>
      <p class="lead"></p>
    </div>
    <div>
      <a href="mailto:shobhita@mit.edu">Email</a> &nbsp/&nbsp
      <a href="data/cv.pdf">CV</a> &nbsp/&nbsp
      <a href="http://linkedin.com/in/shobsund/">Linkedin</a>
      <br>
      <a href="https://github.com/ssundaram21/">Github</a> &nbsp/&nbsp
      <a href="https://scholar.google.com/citations?user=tlTVtZ4AAAAJ&hl=en&authuser=1">Google Scholar</a>
      <p></p>
    </div>
    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="#about">Home</a>
      <a class="sidebar-nav-item" href="#recent-news">Recent News</a>
      <a class="sidebar-nav-item" href="#research">Publications</a>
      <a class="sidebar-nav-item" href="#invited">Invited Talks</a>
      <a class="sidebar-nav-item" href="#service">Service</a>
      <!-- <a class="sidebar-nav-item" href="#writing">Other Writing</a> -->

    </nav>

<!--    <p class="sidebar-sticky">&copy; 2021. All rights reserved.</p>-->
  </div>
</div>


    <div class="content container">
      <div class="page">
  <h1 id="about">About Me</h1>
        <p>
        I'm a third-year PhD student at MIT, advised byÂ <a href="https://web.mit.edu/phillipi/">Phillip Isola</a>. I am supported by the <a href="https://www.nsfgrfp.org">NSF Graduate Research Fellowship</a>, and previously by the MIT HDTV Grand Alliance Fellowship. I am broadly interested in generative models and data-centric approaches to deep learning. At the moment I'm working on the following questions:
        </p>
        <ol>
          <li><b>Scaling synthetic data: </b> How can we improve the scalability and efficiency of synthetic data?</li>
          <li><b>Generating useful data: </b>What is the tradeoff between quality and "surprise" of synthetic samples for a particular learner?</li>
          <li><b>Science of training data: </b>Can we better understand, improve, and sample from real training datasets to enable more efficient learning and scaling?</li>
        </ol>
    <p>
      Previously I got my bachelors in Computer Science and in Mathematics at MIT, working at the <a href="https://cbmm.mit.edu">MIT Center for Brains, Minds, and Machines</a> with <a href="https://www.sinhalab.mit.edu">Pawan Sinha</a> and <a href="https://www.mit.edu/~xboix/">Xavier Boix</a>. In the past I've also been fortunate to intern at <a href="https://deepmind.google">DeepMind</a> (large language models), <a href="https://www.deshaw.com">D. E. Shaw</a> (reinforcement learning research), <a href="https://www.apple.com">Apple</a> (applied machine learning), and <a href="https://www.twosigma.com">Two Sigma</a> (software engineering). In my free time I enjoy hiking, running, and tennis.
    </p>

<h1 id="recent-news">Recent News</h1>
<ul>
  <li><strong id="news">[Apr 2025]</strong> Attending ICLR! I'm presenting our work on <a href="https://arxiv.org/abs/2412.16156">personalized representations</a> at the main conference.</li>
  <li><strong id="news">[Apr 2025]</strong> Gave a talk at the Stanford NeuroAILab.</li>
  <li><strong id="news">[Mar 2025]</strong> Gave a talk at <a href="https://cohere.com/research">Cohere for AI</a> (<a href="https://www.youtube.com/watch?v=vPBzjhdTTD8&list=PLLalUvky4CLJKDaiWCumhsJpHNDhZeVll&index=3&t=1s">recording here</a>).</li>
  <li><strong id="news">[Jan 2025]</strong> Our paper <a href="https://arxiv.org/abs/2412.16156">Personalized Representation from Personalized Generation</a> was accepted to ICLR 2025.</li>
  <li><strong id="news">[Dec 2024]</strong> Our preprint <a href="https://arxiv.org/abs/2412.21127">What Makes for a Good Stereoscopic Image</a> is on Arxiv.</li>
  <li><strong id="news">[Dec 2024]</strong> Attending NeurIPS! I'm presenting our work on <a href="https://arxiv.org/abs/2410.10817">perceptual alignment</a> at the main conference.</li>
  <li><strong id="news">[Oct 2024]</strong> Gave a talk at the ECCV "Efficient Text-to-Image and Text-to-3D Modeling Tutorial" (also co-organized) on <a href="https://ssundaram21.github.io/data/ImageEvaluationMethods.pdf">Evaluating Text-to-Image Models</a>.</li>
  <li><a href="#" id="more-link">More...</a></li>
  <div id="more-news" style="display:none;">
    <li><strong id="news">[Sep 2024]</strong> Our paper <a href="https://arxiv.org/abs/2410.10817">When Does Perceptual Alignment Benefit Vision Representations?</a> was accepted to NeurIPS 2024.</li>
    <li><strong id="news">[Jul 2024]</strong> Attending the International Computer Vision Summer School (ICVSS) 2024.</li>
    <li><strong id="news">[Jun 2024]</strong> Attending CVPR! Co-organizing the <a href="https://syndata4cv.github.io/cvpr2024.html">Synthetic Data for Computer Vision Workshop</a></li>
    <li><strong id="news">[Dec 2023]</strong> Attending NeurIPS! I'm presenting <a href="https://arxiv.org/abs/2306.09344">DreamSim</a> at the main conference.</li>
    <li><strong id="news">[Oct 2023]</strong> Gave a talk on <a href="https://arxiv.org/abs/2306.09344">DreamSim</a> at Adobe.</li>
    <li><strong id="news">[Sep 2023]</strong> Our paper <a href="https://arxiv.org/abs/2306.09344">DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data</a> was accepted to NeurIPS 2023.</li>
    <li><strong id="news">[Jul 2023]</strong> Gave a talk on <a href="https://arxiv.org/abs/2306.09344">DreamSim</a> at Voxel51.</li>
    <li><strong id="news">[Sep 2022]</strong> Started my PhD at MIT!</li>
    <li><strong id="news">[Apr 2022]</strong> Awarded the NSF GFRP and HDTV Grand Alliance Fellowships.</li>
  </div>
  <script>
    document.getElementById('more-link').addEventListener('click', function(event) {
      event.preventDefault();
      var moreNews = document.getElementById('more-news');
      if (moreNews.style.display === 'none') {
        moreNews.style.display = 'block';
        this.textContent = 'Less...';
      } else {
        moreNews.style.display = 'none';
        this.textContent = 'More...';
      }
    });
  </script>
</ul>

   


<!-- <p><strong id="news">[January 2025]</strong> Our paper <a href="https://arxiv.org/abs/2412.16156">Personalized Representation from Personalized Generation</a> was accepted to ICLR 2025.</p>
<p><strong id="news">[December 2024]</strong> Attending NeurIPS! I'm presenting <a href="https://arxiv.org/abs/2410.10817">When Does Perceptual Alignment Benefit Vision Representations?</a> at the main conference.</p>
<p><strong id="news">[October 2024]</strong> I gave a talk at the ECCV "Efficient Text-to-Image and Text-to-3D modeling Tutorial" (also co-organized) on <a href="https://ssundaram21.github.io/data/ImageEvaluationMethods.pdf">Evaluating Text-to-Image Models</a>.</p>
<p><strong id="news">[September 2024]</strong> Our paper <a href="https://arxiv.org/abs/2410.10817">When Does Perceptual Alignment Benefit Vision Representations?</a> was accepted to NeurIPS 2024.</p>
<p><strong id="news">[July 2024]</strong> Attending the International Computer Vision Summer School (ICVSS) 2024.</p>
<p><strong id="news">[June 2024]</strong> Attending CVPR! Co-organizing the <a href="https://syndata4cv.github.io/cvpr2024.html">Synthetic Data for Computer Vision Workshop</a></p> -->

<h1 id="research">Publications</h1>
<p><em>* indicates equal contribution</em></p>        

<table id="publications-table"><tbody>
      <tr>
        <td class="paper_icon" >
          <div>
          <img src="images/stereo_icon.png" alt="blind-date" width="190" height="120">
          </div>
        </td>
        <td class="paper_content" width="75%" valign="middle">
          <a href="https://arxiv.org/abs/2412.21127">
            <papertitle>What Makes for a Good Stereoscopic Image?</papertitle>
          </a>
          <br>
          Netanel Y. Tamir*, Shir Amir*, Ranel Itzhaky, Noam Atia, <strong>Shobhita Sundaram</strong>, Stephanie Fu, Ron Sokolovsky, Phillip Isola, Tali Dekel, Richard Zhang, Miriam Farber
          <br>
          <em>CVPR Computer Vision for Metaverse Workshop</em>, 2025. 
          <br>
          <a href="https://arxiv.org/abs/2412.16156" class="button-link">Paper</a>
        </td>
      </tr>
      
        <tr>
            <td class="paper_icon" >
              <div>
              <img src="images/prpg_icon.jpg" alt="blind-date" width="190" height="120">
              </div>
            </td>
            <td class="paper_content" width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2412.16156">
                <papertitle>Personalized Representation from Personalized Generation</papertitle>
              </a>
              <br>
              <strong>Shobhita Sundaram*</strong>, Julia Chae*, Yonglong Tian, Sara Beery<sup>Â§</sup>, Phillip Isola<sup>Â§</sup>.
              <br>
              <em>ICLR</em>, 2025. 
              <br>
              <a href="https://arxiv.org/abs/2412.16156" class="button-link">Paper</a>  <a href="https://personalized-rep.github.io" class="button-link">Website</a> <a href="https://github.com/ssundaram21/personalized-rep" class="button-link">Code</a>  <a href="https://huggingface.co/datasets/chaenayo/PODS" class="button-link">Data</a>
            </td>
          </tr>

          <tr>
          <td class="paper_icon" >
            <div>
            <img src="images/repalign_icons.png" alt="blind-date" width="190" height="120">
            </div>
          </td>
          <td class="paper_content" width="75%" valign="middle">
            <a href="https://arxiv.org/abs/2410.10817">
              <papertitle>When Does Perceptual Alignment Benefit Vision Representations?</papertitle>
            </a>
            <br>
            <strong>Shobhita Sundaram*</strong>, Stephanie Fu*, Lukas Muttenthaler, Netanel Tamir, Lucy Chai, Simon Kornblith, Trevor Darrell, Phillip Isola.
            <br>
            <em>NeurIPS</em>, 2024. 
            <br>
            <a href="https://arxiv.org/abs/2410.10817" class="button-link">Paper</a> <a href="https://percep-align.github.io" class="button-link">Website</a> <a href="https://github.com/ssundaram21/dreamsim" class="button-link">Code</a>
          </td>
        </tr>

          <tr>
            <td class="paper_icon" >
              <div class="one">
              <img src="images/dreamsim_img2.png" alt="blind-date" width="160" height="160">
              </div>
            </td>
            <td class="paper_content" width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2306.09344">
                <papertitle>DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data</papertitle>
              </a>
              <br>
              Stephanie Fu*, Netanel Tamir*, <strong>Shobhita Sundaram*</strong>, Lucy Chai, Richard Zhang, Tali Dekel, Phillip Isola.
              <br>
              <em>NeurIPS</em>, 2023 <strong>(spotlight)</strong>. 
              <br>
              <a href="https://arxiv.org/abs/2306.09344" class="button-link">Paper</a> <a href="https://dreamsim-nights.github.io" class="button-link">Website</a> <a href="https://github.com/ssundaram21/dreamsim" class="button-link">Code</a> 
            </td>
          </tr>
  
          <tr>
            <td class="paper_icon" >
              <div class="one">
              <img src="images/symmetry_icons.jpg" alt="blind-date" width="160" height="160">
              </div>
            </td>
            <td class="paper_content" width="75%" valign="middle">
              <a href="https://www.nature.com/articles/s41598-022-25219-w">
                <papertitle>Recurrent connections facilitate symmetry perception in deep networks</papertitle>
              </a>
              <br>
              <strong>Shobhita Sundaram*</strong>, Darius Sinha*, Matthew Groth, Tomotake Sasaki, Xavier Boix
              <br>
              <em>Scientific Reports</em>, 2022. 
              <br>
              <em>Workshop on Generalization Beyond the Training Distribution in Brains and Machines, ICLR</em> 2021.
              <br>
              <a href="https://www.nature.com/articles/s41598-022-25219-w" class="button-link">Paper</a> <a href="https://github.com/ssundaram21/symmetry" class="button-link">Code</a> <a href="https://drive.google.com/file/d/1Wm-BePPyZajw9of_9IRZW6c8u4eD7w_B/view?usp=sharing" class="button-link">Poster</a>
            </td>
          </tr>

          <tr>
            <td class="paper_icon">
              <div class="one">
              <img src="images/ganImage.png" alt="clean-usnob" width="160" height="160">
                </div>
            </td>
            <td class="paper_content">
              <a href="http://128.84.4.18/abs/2107.02970">
                <papertitle>GAN-based Data Augmentation for Chest X-ray Classification</papertitle>
              </a>
              <br>
              <strong>Shobhita Sundaram*</strong>, Neha Hulkund*
              <br>
              <em>Workshop on Applied Data Science for Healthcare, KDD</em> 2021
              <p><a href="https://arxiv.org/abs/2107.02970" class="button-link">Paper</a></p>
            </td>
          </tr>

          <tr>
            <td class="paper_icon">
              <div class="one">
              <img src="images/insidenessIcon.png" alt="clean-usnob" width="160" height="160">
              </div>
            </td>
            <td class="paper_content">
              <a href="https://direct.mit.edu/neco/article/33/9/2511/102620/Do-Neural-Networks-for-Segmentation-Understand">
                <papertitle>Do Neural Networks for Segmentation Understand Insideness?</papertitle>
              </a>
              <br>
              Kimberly Villalobos*,  Vilim Stih*, Amineh Ahmadinejad*, <strong>Shobhita Sundaram</strong>, Jamell Dozier, Andrew Francl, Frederico Azevedo, Tomotake Sasaki, Xavier Boix
              <br>
              <em>Neural Computation</em>, 2021
              <p><a href="https://direct.mit.edu/neco/article/33/9/2511/102620/Do-Neural-Networks-for-Segmentation-Understand" class="button-link">Paper</a> <a href="https://github.com/xboix/insideness" class="button-link">Code</a></p>
            </td>
          </tr>

        </tbody></table>

<h1 id="invited">Invited Talks</h1>
          <ul>
                <li><strong>Stanford NeuroAILab, April 2025. </strong> <em>Representation Learning with Perceptual Alignment.</em></li>
                <li><strong><a href="https://cohere.com/research">Cohere for AI</a>, March 2025. </strong> <em>Personalized Representation from Personalized Generation.</em></li> <a href="https://www.youtube.com/watch?v=vPBzjhdTTD8&list=PLLalUvky4CLJKDaiWCumhsJpHNDhZeVll&index=3&t=1s">[Recording]</a>
                <li> <strong><a href="https://efficient-genai.github.io">Efficient Text-to-Image and Text-to-3D modeling Tutorial</a>, ECCV 2024. </strong> <em> Evaluating Text-to-Image Models.</em></li> <a href="https://ssundaram21.github.io/data/ImageEvaluationMethods.pdf">[Slides]</a>
                <li> <strong>Adobe GenTech Seminar, October 2023. </strong> <em>DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data.</em></li>
                <li> <strong>Voxel51 Computer Vision Meetup, July 2023.</strong> <em>DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data.</em></li>
          </ul>

        
<h1 id="service">Service</h1>
        <ul>
          <li> <strong>Organizer: <a href="https://efficient-genai.github.io">Efficient Text-to-Image and Text-to-3D modeling Tutorial</a></strong>, ECCV 2024 </li>      
          <li> <strong>Organizer: <a href="https://syntheticdata4cv.wordpress.com">Synthetic Data for Computer Vision Workshop</a></strong>, CVPR 2024 </li>
          <li> <strong>Reviewer: </strong>ECCV 2024</a></li>
          </ul>

        
<!-- <h1 id="writing">Other Writing</h1>
        <ul>
                <li> <a href="https://sciencepolicyreview.org/2021/08/catalyzing-quantum-leap/">MIT Science Policy review (Associate Editor)</a> </li>
                <li> <a href="https://issuu.com/mitchroma/docs/fall2019">MIT Chroma: "Rebuilding Despite the Risks"</a></li>
          </ul>
</div> -->

    </div>

  </body>
</html>
